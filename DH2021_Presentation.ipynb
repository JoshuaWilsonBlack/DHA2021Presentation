{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01502021",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Philosophical Writing in Early New Zealand Newspapers\n",
    "## A Case Study of Specialised Corpus Construction from Large Digitised Newspaper Datasets\n",
    "### DH2021 - University of Canterbury | Te Whare Wānanga o Waitaha\n",
    "Joshua Black  <br/>\n",
    "New Zealand Institute of Language, Brain and Behaviour | Te Kāhui Roro Reo <br />\n",
    "joshua.black@canterbury.ac.nz  <br />\n",
    "black.joshuad@gmail.com  \n",
    "\n",
    "GitHub repository: https://github.com/JoshuaDavidBlack/newspaper-philosophy-methods <br/>\n",
    "Project dashboard: https://nz-newspaper-philosophy.herokuapp.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5e3df5a",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import html\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "import re\n",
    "\n",
    "from IPython.display import HTML\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "\n",
    "from jupyter_dash import JupyterDash\n",
    "import dash_cytoscape as cyto\n",
    "from dash import dcc\n",
    "from dash import html as dash_html\n",
    "from dash.dependencies import Input, Output, State\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "random.seed(10)",
    "\n",
    "JupyterDash.infer_jupyter_proxy_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b620db4",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Overview\n",
    "\n",
    "1. **Content Motivation:** telling a broader story about philosophy in New Zealand through newspaper content.\n",
    "2. **Methodological Motivation:** overcoming reliance on keyword search in OCR-generated digital archives.\n",
    "3. **Problem:** how to construct a specialised corpus from newspaper digitisations which can be a target for digital humanities investigation.\n",
    "4. **Solution:** an 'iterative bootstrapping' process of candidate corpus exploration, article labelling, and text-classifier training.\n",
    "5. **Result:** a corpus which reveals interesting features of philosophical discussion in NZ, including:\n",
    "  1. debates over evolution and creation, and\n",
    "  2. debates over whether the education system ought to be secular or not."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eed975a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Content Motivation\n",
    "\n",
    "- History of (academic) philosophy in New Zealand largely absent before middle of 20th century:\n",
    " - 'many of those who had longstanding chairs published next to nothing' (Davies & Helgeby 2014, 24)\n",
    "- Another gap in 'history of philosophy' in general: philosophy outside academic publications.\n",
    "- Newspaper material offers an opportunity to address both gaps.\n",
    " - In early colonial NZ, newspapers, rather than monographs or journal articles, were 'the fundamental infrastructure for intellectual life' (Ballantyne 2012, 57)\n",
    " - A wider class of contributers (including journalists themselves, letters to the editor, and reports of public lectures).\n",
    "- [Release](https://natlib.govt.nz/about-us/open-data/papers-past-metadata/papers-past-newspaper-open-data-pilot) of bulk of pre-1900 English-langauge newspaper content by The National Library of New Zealand | Te Puna Mātauranga o Aotearoa.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc47903f",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"images/oo.png\" style=\"width:100%; margin:auto\"/>                                                   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7105afab",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## What is philosophy?\n",
    "\n",
    "- Some 19th Century usage:\n",
    " - “Philosophy arises when, not content with the facts of existence (that is, of the world), men proceed to the inquiry into their reasons, and ultimately into their unconditioned reason i.e. their rationality.” (Erdmann 1890, 1)\n",
    " - \"Philosophy --- we define to be --- the progressive rational system of the principles presupposed and ascertained by the particular sciences, in their relation to ultimate Reality\" (Ladd 1890, 27).\n",
    "- Philosophy is always more-or-less connected to _reason_.\n",
    " - We're supposed to _reason_ for philosophical conclusions rather than (directly) appealing to tradition or personal insight.\n",
    "- For our purposes: philosophy occurs when claims about \"ultimate reality\" are used in rational argument.\n",
    "\n",
    "- Need to mention something about contestedness? Laerke 2013, 9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "010ac107",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Methodological Motivation\n",
    "\n",
    "- How should the methodology of historical research change with the introduction of large OCR-generated digital archives?\n",
    "- Widespread dissatisfaction with keyword searching:\n",
    " - Only allows you to make existence proof arguments (Owens & Padilla 2021).\n",
    " - Where is the context? - we can always string anecdotes together (Putnam 2016).\n",
    " - OCR problems - an unclear collection of material is unsearchable (Hitchcock 2013)\n",
    " - Traditional citation practices are now deceptive. (Hitchcock 2013)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d831314f",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- The same literature calls for a different orientation:\n",
    " - \"What can we do that we couldn't do before?\" (Gibbs & Owens 2013; Nicholson 2013)\n",
    " - \"Source as data\" approach (Owens & Padilla 2021)\n",
    " - Use of text mining techniques to provide context (Owens & Padilla 2021, Putnam 2013).\n",
    " - Engagement with big data analysis to move from \"piles of books to subtle maps of meaning\" (Hitchcock 2013).\n",
    "- This project is an experiment in this orientation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0586a65",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# The Problem\n",
    "\n",
    "- The Papers Past Newspaper Open Data Pilot release contains around 1.5 million pages of newspaper content (315GB compressed).\n",
    "- Application of text mining to this dataset won't give insight into _philosophical discourse_ in NZ newspapers.\n",
    " - ...the 'philosophical' material is such a small fraction it wouldn't show up (final corpus: 0.4% of dataset).\n",
    "- This is a general problem: creating specialist corpora from digital newspaper archives.\n",
    "- We want to do this in a way which avoids the problems of keyword searching and which does not rely on accurate OCR.\n",
    "- Additional aim: offer any solution in an accessible way for other researchers.\n",
    " - Publically available [Jupyter notebooks](https://github.com/JoshuaDavidBlack/newspaper-philosophy-methods),\n",
    " - Publically available ways to interact with the [resulting corpus.](https://nz-newspaper-philosophy.herokuapp.com/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7412a48",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# A Solution\n",
    "\n",
    "<img src=\"images/flow_diagram.png\" style=\"margin:auto\"/> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f183d692",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Preprocessing\n",
    "\n",
    "- The data comes in [METS/ALTO](https://veridiansoftware.com/knowledge-base/metsalto/) XML format. This is widespread in newspaper digitisation.\n",
    " - It contains both physical and logical descriptions of original newspaper issues and pages (METS for issue structure, ALTO files for each page).\n",
    "- Data released as title-year compressed files. For each of these we:\n",
    " 1. iterate through each issue, collecting a list of articles and corresponding text blocks from the METS file,\n",
    "   - **NB:** articles are distinguished from advertisements.\n",
    " 2. iterate through the ALTO files, collecting text blocks for each article.\n",
    "- We save the processed data in a series of compressed \"slices\" of the dataset (~7.6 million items, 8GB).\n",
    " - Each slice is a [Pandas](https://pandas.pydata.org/) dataframe\n",
    "- The result: plain text for each item in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02636960",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Corpus Exploration\n",
    "\n",
    "- The corpus exploration stage starts with a _candidate corpus_. We evaluate whether this corpus is satisfactory.\n",
    "- So how do we get our first one? Either:\n",
    " 1. the whole dataset, or\n",
    " 2. our old friend: keyword search (recommended).\n",
    "- Many methods can be used here. In the [notebook](https://github.com/JoshuaDavidBlack/newspaper-philosophy-methods):\n",
    "    - manual inspection,\n",
    "    - concordancing,\n",
    "    - collocations,\n",
    "    - cooccurrence networks,\n",
    "    - topic modelling.\n",
    "- Each of these gives insight into the content of the candidate corpus."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3174c768",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Aside: Cooccurrence networks\n",
    "\n",
    "- A way to represent the cooccurrence of terms within an item.\n",
    "- Statistically significant cooccurrences enable us to something of how a word is being used.\n",
    "- Implemented using [Dash](https://dash.plotly.com/).\n",
    "- Examples available [here](https://nz-newspaper-philosophy.herokuapp.com/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "215a0240",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- At end of this stage: is the corpus good enough?\n",
    " - Are there lots of unwanted items?\n",
    " - Do I have reason to think I'm missing something?\n",
    "- If the corpus is satisfactory, we have what we were after.\n",
    "- If not, we move on to the labelling stage.\n",
    " - Notes should be kept throughout on wanted/unwanted items."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a848a11",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Labelling\n",
    "\n",
    "- There's no pain free way to do this!\n",
    "- We need a _labelling scheme_. In this case it's vague:\n",
    "  - Philosophy: is the majority of the article 'philosophical discourse’?\n",
    "  - A broad definition: does it argue for or appeal to ideas of ‘ultimate reality’ or ‘ultimate value’.\n",
    "  - I also included sublabels for writing type and philosophy type. Even if not used for classification these can be useful auxilliary variables for evaluating what kind of material is being handled by the model best.\n",
    "- I've created a [Dash](https://dash.plotly.com/) dashboard to enable labelling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f256d111",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "with open('data/codes2names_web.pickle', 'rb') as fin:\n",
    "    CODES2NAMES_WEB = pickle.load(fin)\n",
    "with open('data/codes2names.pickle', 'rb') as fin:\n",
    "    CODES2NAMES = pickle.load(fin)\n",
    "    \n",
    "labels = pd.DataFrame(\n",
    "    columns=[\n",
    "        'Text', 'Notes',  # See below for discussion of labels.\n",
    "        'Philosophy', 'Philosophy Type', 'Readable', 'Writing Type', \n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb57788e",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def add_title_and_year(df):\n",
    "    \"\"\"Add 'Newspaper', 'Year', and 'Date' column to dataframe with\n",
    "    'Text' column.\"\"\"\n",
    "    df['Newspaper'] = df.index.map(lambda x: x[0:x.find('_')])\n",
    "    df['Date'] = df.index.map(lambda x: x[x.find('_')+1:x.find('_')+9])\n",
    "    \n",
    "\n",
    "def escape_markdown(string):\n",
    "    \"\"\"Escape characters which have functions in markdown strings.\n",
    "    Return escaped string.\"\"\"\n",
    "\n",
    "    markdown_escape_chars = r\"\\`*_{}[]<>()#+-.!|\"\n",
    "    for escape_char in markdown_escape_chars:\n",
    "        string = string.replace(escape_char, \"\\\\\"+escape_char)\n",
    "\n",
    "    return string\n",
    "\n",
    "def text_as_markdown(index, dataframe, boldface=None):\n",
    "    \"\"\"Render article corresponding to index in dataframe as markdown\n",
    "    string. Any matches for boldface are rendered in bold.\n",
    "    \"\"\"\n",
    "\n",
    "    date = index[index.find('_')+1:index.find('_')+9]\n",
    "    newspaper = index[0:index.find('_')]\n",
    "\n",
    "    title = (dataframe.loc[index, 'Title'])\n",
    "    title = escape_markdown(title)\n",
    "\n",
    "    web_prefix = \"https://paperspast.natlib.govt.nz/newspapers/\"\n",
    "    year = date[0:4]\n",
    "    month = date[4:6]\n",
    "    day = date[6:8]\n",
    "    web_address = f\"{web_prefix}{CODES2NAMES_WEB[newspaper]}/{year}/{month}/{day}\"\n",
    "\n",
    "    text_blocks = dataframe.loc[index, 'Text']\n",
    "    text = ''\n",
    "    for block in text_blocks:\n",
    "        paragraph = escape_markdown(block)\n",
    "        text += paragraph + '\\n\\n'\n",
    "\n",
    "    if boldface:\n",
    "        match = re.search(boldface, text)\n",
    "        if match:\n",
    "            text = re.sub(boldface, f'***{match.group(0)}***', text)\n",
    "\n",
    "    markdown_text = f\"\"\"## {title}\n",
    "\n",
    "*{CODES2NAMES[newspaper]}*\n",
    "\n",
    "{day}/{month}/{year}\n",
    "\n",
    "[View issue on Papers Past]({web_address})\n",
    "\n",
    "{text}\n",
    "\"\"\"\n",
    "\n",
    "    return markdown_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bac2fd48",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "to_label = pd.read_pickle('data/sample_corpus.tar.gz')\n",
    "add_title_and_year(to_label)\n",
    "item_names_formatted = [\n",
    "    {'label': f'{to_label[\"Title\"].loc[i]} ({i})', 'value': i} \n",
    "    for i in to_label.index\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c395114",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "app = JupyterDash(__name__, external_stylesheets=['https://codepen.io/chriddyp/pen/bWLwgP.css'])\n",
    "\n",
    "#For readability, the control panel is defined before the full app layout.\n",
    "control_panel = [\n",
    "    dash_html.P('Readable?'),\n",
    "    dcc.RadioItems(\n",
    "        id='readable-radio',\n",
    "        options=[\n",
    "            {'label': 'True', 'value': True},\n",
    "            {'label': 'False', 'value': False}\n",
    "        ]\n",
    "    ),\n",
    "    dash_html.P('Philosophy?'),\n",
    "    dcc.RadioItems(\n",
    "        id='philosophy-radio',\n",
    "        options=[\n",
    "            {'label': 'True', 'value': True},\n",
    "            {'label': 'False', 'value': False}\n",
    "        ]\n",
    "    ),\n",
    "    dash_html.P('Philosophy Type?'),\n",
    "    dcc.RadioItems(\n",
    "        id='phil-type-radio',\n",
    "        options=[\n",
    "            {'label': 'Religion/Science', 'value': 'r'},\n",
    "            {'label': 'Ethics/Politics', 'value': 'e'},\n",
    "            {'label': 'Other', 'value': 'o'},\n",
    "            {'label': 'N/A', 'value': None}\n",
    "        ]\n",
    "    ),\n",
    "    dash_html.P('Writing Type?'),\n",
    "    dcc.RadioItems(\n",
    "        id='write-type-radio',\n",
    "        options=[\n",
    "            {'label': 'Report of public event', 'value': 'p'},\n",
    "            {'label': 'Letter to editor', 'value': 'l'},\n",
    "            {'label': 'First order', 'value': 'f'},\n",
    "            {'label': 'N/A', 'value': None}\n",
    "        ]\n",
    "    ),\n",
    "    dash_html.P('Notes:'),\n",
    "    dcc.Textarea(\n",
    "        id='notes-area',\n",
    "        style={'width': '100%'}\n",
    "    ),\n",
    "    dash_html.Button('Update', id='submit-val', n_clicks=0, style={'margin':'5px'}),\n",
    "    dash_html.P(id='update-message', style={'display':'none'}) # This div allows the update button to work.\n",
    "]\n",
    "\n",
    "app.layout = dash_html.Div([\n",
    "    dash_html.H2('Label Newspaper Items'),\n",
    "    dash_html.P('Item'),\n",
    "    dcc.Dropdown(\n",
    "        id='item-selection',\n",
    "        options=item_names_formatted,\n",
    "        value=item_names_formatted[0]['value'],\n",
    "        style={'width': '80%', 'margin': '10px'}\n",
    "    ),\n",
    "    dash_html.Div([\n",
    "        dash_html.Div(\n",
    "            dash_html.Div(\n",
    "                dcc.Markdown(\n",
    "                    id='article-display',\n",
    "                    children=text_as_markdown(to_label.index[0], to_label),\n",
    "                ),\n",
    "            style={\n",
    "                'width': '700px',\n",
    "                'margin': 'auto'\n",
    "                }    \n",
    "            ),\n",
    "        style={\n",
    "                'width': '70%', \n",
    "                'display': 'inline-block',\n",
    "                'padding': '15px',\n",
    "                'margin': '10px'\n",
    "            }\n",
    "        ),\n",
    "        dash_html.Div(\n",
    "            control_panel,\n",
    "            style={\n",
    "                'width': '15%', \n",
    "                'display': 'inline-block', \n",
    "                'vertical-align': 'top', \n",
    "                'padding': '50px',\n",
    "                'border': 'solid',\n",
    "                #'position': 'fixed',\n",
    "                'margin': '10px'\n",
    "            }\n",
    "        )\n",
    "    ])    \n",
    "])\n",
    "\n",
    "# When new item chosen, load item text and any labels.\n",
    "@app.callback(\n",
    "    [Output(component_id='article-display', component_property='children'),\n",
    "    Output(component_id='readable-radio', component_property='value'),\n",
    "    Output(component_id='philosophy-radio', component_property='value'),\n",
    "    Output(component_id='phil-type-radio', component_property='value'),\n",
    "    Output(component_id='write-type-radio', component_property='value'),\n",
    "    Output(component_id='notes-area', component_property='value')],\n",
    "    [Input(component_id='item-selection', component_property='value')]\n",
    ")\n",
    "def load_new_markdown_and_labels(item_id):\n",
    "    text = text_as_markdown(item_id, to_label)\n",
    "    readable = philosophy = phil_type = write_type = notes =  None # default value.\n",
    "    if item_id in labels.index:\n",
    "        readable = labels.loc[item_id, 'Readable']\n",
    "        philosophy = labels.loc[item_id, 'Philosophy']\n",
    "        phil_type = labels.loc[item_id, 'Philosophy Type']\n",
    "        write_type = labels.loc[item_id, 'Writing Type']\n",
    "        notes = labels.loc[item_id, 'Notes']\n",
    "    return text, readable, philosophy, phil_type, write_type, notes\n",
    "\n",
    "# Update labels when 'update' button pressed.\n",
    "@app.callback(\n",
    "    Output(component_id='update-message', component_property='children'),\n",
    "    [Input(component_id='submit-val', component_property='n_clicks')],\n",
    "    [State(component_id='readable-radio', component_property='value'),\n",
    "    State(component_id='philosophy-radio', component_property='value'),\n",
    "    State(component_id='phil-type-radio', component_property='value'),\n",
    "    State(component_id='write-type-radio', component_property='value'),\n",
    "    State(component_id='item-selection', component_property='value'),\n",
    "    State(component_id='notes-area', component_property='value')]\n",
    ")\n",
    "def update_labels(n_clicks, readable, philosophy, phil_type, write_type, item_id, notes):\n",
    "    if n_clicks > 0:\n",
    "        labels.loc[item_id, \"Readable\"] = readable\n",
    "        labels.loc[item_id, \"Philosophy\"] = philosophy\n",
    "        labels.loc[item_id, \"Philosophy Type\"] = phil_type\n",
    "        labels.loc[item_id, \"Writing Type\"] = write_type\n",
    "        labels.loc[item_id, \"Text\"] = to_label.loc[item_id, 'Text']\n",
    "        labels.loc[item_id, \"Notes\"] = notes\n",
    "        #labels.to_pickle(f'../Labels/labels_{ITERATION}.tar.gz')\n",
    "    return 'Labels updated'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "80b54296",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://127.0.0.1:8050/ (Press CTRL+C to quit)\n",
      "127.0.0.1 - - [18/Jun/2022 12:03:58] \"GET /_alive_293828bb-8fb8-45ba-963e-cb86676faa29 HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dash app running on http://127.0.0.1:8050/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [18/Jun/2022 12:07:07] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [18/Jun/2022 12:07:07] \"GET /_dash-component-suites/dash/deps/polyfill@7.v2_0_0m1632235559.12.1.min.js HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [18/Jun/2022 12:07:07] \"GET /_dash-component-suites/dash/deps/prop-types@15.v2_0_0m1632235559.7.2.min.js HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [18/Jun/2022 12:07:07] \"GET /_dash-component-suites/dash/deps/react-dom@16.v2_0_0m1632235559.14.0.min.js HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [18/Jun/2022 12:07:07] \"GET /_dash-component-suites/dash/deps/react@16.v2_0_0m1632235559.14.0.min.js HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [18/Jun/2022 12:07:07] \"GET /_dash-component-suites/dash_cytoscape/dash_cytoscape.v0_2_0m1619800188.min.js HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [18/Jun/2022 12:07:07] \"GET /_dash-component-suites/dash/dcc/dash_core_components-shared.v2_0_0m1632235559.js HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [18/Jun/2022 12:07:07] \"GET /_dash-component-suites/dash/dash-renderer/build/dash_renderer.v2_0_0m1632235559.min.js HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [18/Jun/2022 12:07:07] \"GET /_dash-component-suites/dash/html/dash_html_components.v2_0_0m1632235559.min.js HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [18/Jun/2022 12:07:07] \"GET /_dash-component-suites/dash/dcc/dash_core_components.v2_0_0m1632235559.js HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [18/Jun/2022 12:07:07] \"GET /_dash-component-suites/dash/dash_table/bundle.v5_0_0m1632235559.js HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [18/Jun/2022 12:07:08] \"GET /_dash-layout HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [18/Jun/2022 12:07:08] \"GET /_dash-dependencies HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [18/Jun/2022 12:07:08] \"GET /_favicon.ico?v=2.0.0 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [18/Jun/2022 12:07:08] \"GET /_dash-component-suites/dash/dcc/async-dropdown.js HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [18/Jun/2022 12:07:08] \"GET /_dash-component-suites/dash/dcc/async-markdown.js HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [18/Jun/2022 12:07:09] \"GET /_dash-component-suites/dash/dcc/async-highlight.js HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [18/Jun/2022 12:07:09] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [18/Jun/2022 12:07:09] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [18/Jun/2022 12:07:13] \"POST /_dash-update-component HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    app.run_server(debug=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d68deac",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Training and Applying a Model\n",
    "\n",
    "- Once we have a set of labels, supervised learning is open to us.\n",
    "- A simple bag-of-words representation of the items by word and frequency count (or [TF-IDF](https://en.wikipedia.org/wiki/Tf%E2%80%93idf) transformation) is the best we can do given OCR.\n",
    " - This excludes more advanced methods which use high quality sequences of data.\n",
    "- A simple classification method is applied: Naive Bayes via [Scikit-Learn](https://scikit-learn.org/).\n",
    " - ...easy to train and performs well for text classification (Zhang 2004)\n",
    "- Cross validation search used to select model parameters.\n",
    " - ...\"do we include n-grams?\", \"how many words in our dictionary?\", etc...\n",
    "- Evaluation of models is both:\n",
    " - quantitative (accuracy, recall, and precision rates)\n",
    " - and qualitative (what are the false positives and negatives and are they edge cases?)\n",
    "- We generate a new candidate corpus by applying the resulting classifier to the processed dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56aba1b5",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## \"Iterative Bootstrapping\"\n",
    "\n",
    "- The phrase: ‘pull yourself up by the bootstraps’:\n",
    "    1. starting with nothing, we add articles to our labelled collection,\n",
    "    2. having collected a number with much higher representation of philosophy than the general dataset,\n",
    "    3. we train and apply a classifier,\n",
    "    4. we use the articles classified as philosophy as a source of new articles to label."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4713a239",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Results\n",
    "\n",
    "- The results reported here come after two iterations of the corpus construction process.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36349e9a",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Labelling\n",
    "\n",
    "<img src=\"images/label_counts.png\" style=\"margin:auto\"/> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4435ea6f",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Quantitative Model Metrics\n",
    "\n",
    "<img src=\"confusion_matrix.png\" style=\"margin:auto\"/> \n",
    "\n",
    "- Accuracy: 89%\n",
    "- Precision: 81%\n",
    "- Recall: 80%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ff2a52",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Qualitative Model Investigation\n",
    "\n",
    "- The false negatives are mostly composite items, such as editorials, in which many topics are covered.\n",
    "    - This represents the possible loss of a whole class of perspectives and must be taken into account when drawing conclusions from the corpus.\n",
    "- We can also look at the terms which the model uses to pick out philosophy:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db275c19",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"images/under_the_hood_2.png\" style=\"margin:auto\"/> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b36ee0",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Corpus Metrics\n",
    "\n",
    "<img src=\"images/corpus_counts.png\" style=\"margin:auto\"/> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e43f205c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Sample Cooccurrence Networks\n",
    "\n",
    "- So what can we learn about English-language philosophical discussion from this corpus?\n",
    "- An example: what is the context of philosophical discussion of evolution in NZ newspapers up to 1900?\n",
    "    - Let's look at some cooccurrence networks.\n",
    "    - (All have 25 primary cooccurences, 5 secondary cooccurrences and use the log Dice statistic)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5846aca",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"images/evolution_ld_25-5.png\" style=\"margin:auto\"/> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7047068e",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"images/salmond_ld_25-5.png\" style=\"margin:auto\"/> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb2128b8",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"images/parker_ld_25-5.png\" style=\"margin:auto\"/> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48dc1cb0",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- From a general search term, we see some of the key ideas associated and some of the local figures prominent in this corpus (Salmond and Parker, both Otago professors).\n",
    "- By looking at networks for Salmond and Parker we see something of their associations very quickly:\n",
    "    - Salmond the philosopher and presbyterian minister,\n",
    "    - Parker the biologist and public lecturer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e53ec393",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"images/education_ld_25-5.png\" style=\"margin:auto\"/> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc85b4ef",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"images/secular_ld_25-5.png\" style=\"margin:auto\"/> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af07755d",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- This corpus suggests a very close link between the idea of secularity and education. Both appear in one anothers networks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c8531f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Conclusion\n",
    "\n",
    "- A quick overview of a method for constructing specialised corpora from a large digitised newspaper archive.\n",
    "- An even quicker look at what the philosophy corpus after two iterations of process can tell us.\n",
    "- For a fuller account of the method, see the [GitHub repository](https://github.com/JoshuaDavidBlack/newspaper-philosophy-methods).\n",
    "- How far have we got beyond keyword searching?\n",
    " - We have placed our queries about, say, evolution within a wider contex of discussion,\n",
    " - However, we still need to be _very careful_ about what conclusions we draw.\n",
    " - Careful inspection of our model shows that we are likely to be missing material from editorial discussions.\n",
    " - We have made progress towards \"networks of meaning\" (cf. Hitchcock 2013)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ef084e6",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# References\n",
    "\n",
    "Ballantyne, Tony. (2012). \"Reading the Newspaper in Colonial Otago\".  _The Journal of New\n",
    "Zealand Studies_ 12.\n",
    "\n",
    "Davies, Martin & Stein Helgeby. (2014) \"Idealist Origins: 1920s and Before\". In: _History of Philosophy\n",
    "in Australia and New Zealand._ Graham Oppy & N. N. Trakakis (Eds). Dordrecht: Springer. 15–54.\n",
    "\n",
    "Gibbs, F., & Owens, T. (2013). \"The Hermeneutics of Data and Historical Writing\". In: _Writing History in the Digital Age._ K. Nawrotzki & J. Dougherty (Eds). University of Michigan Press.\n",
    "\n",
    "Hitchcock, Tim. (2013). \"Confronting the Digital\". _The Journal of the Social History Society_ 10(1). 9-23.\n",
    "\n",
    "Nicholson, Bob. (2013). \"The Digital Turn: Exploring the methodological possibilities of digital newspaper archives\". _Media History_ 19(1). 57-73.\n",
    "\n",
    "Putnam, L. (2016). \"The transnational and the text-searchable: Digitized sources and the shadows they cast\". _The\n",
    "American Historical Review._ 121(2). 377–402.\n",
    "\n",
    "Harry Zhang. (2004). \"The Optimality of Naive Bayes\". In: _Proceedings of the Seventeenth International Florida Artificial Intelligence Research Society Conference, FLAIRS 2004._ Valerie Barr and Zdravko Markov (Eds). 562–567."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "rise": {
   "theme": "serif"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
